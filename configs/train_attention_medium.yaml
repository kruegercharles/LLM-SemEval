model_name : attention
backbone: 'roberta-base'
data: '../data/data_15k.json'
model_path: '../outputs/models/task_a/large/attention'
stat_path: '../outputs/statistics/task_a/large/attention'
test: 'a'
weighted: False
mapping: full
num_labels: 7
lr: 1e-5
epochs: 8
batch_size: 32